{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer leaning using ResNet50 \n",
    "Due to the small image size, we next tried transfer leaning using a commonly used pre-trained model ResNet50. The result also suggests overfitting of the training data and labeling all testing data into one category. This is likely due to ResNet50 was not previously trained on x-ray images, and features it has learned might be distracting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/jtian/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/Users/jtian/anaconda3/lib/python3.7/site-packages/keras/utils/conv_utils.py:82: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.copy(kernel[slices])\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "HEIGHT = 200\n",
    "WIDTH = 200\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', \n",
    "                      include_top=False, \n",
    "                      input_shape=(HEIGHT, WIDTH,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "def build_finetune_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        # New FC layer, random init\n",
    "        x = Dense(fc, activation='relu')(x) \n",
    "        x = Dropout(dropout)(x)\n",
    "\n",
    "    # New softmax layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x) \n",
    "    \n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [\"0\", \"1\"]\n",
    "FC_LAYERS = [1024, 1024]\n",
    "dropout = 0.5\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      fc_layers=FC_LAYERS, \n",
    "                                      num_classes=len(class_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train=np.load(\"./X_train.npy\")\n",
    "Y_train=np.load(\"./Y_train.npy\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train[:,0,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "rgb_batch = np.repeat(X[..., np.newaxis], 3, -1)\n",
    "print(rgb_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "finetune_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 82s 411ms/step - loss: 7.0374 - acc: 0.5050\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 81s 407ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 82s 408ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 83s 415ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 88s 439ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 83s 417ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 83s 416ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 84s 418ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 84s 419ms/step - loss: 8.0590 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c298455c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_model.fit(rgb_batch, Y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "X_test=np.load(\"./X_test.npy\")\n",
    "Y_test=np.load(\"./Y_test.npy\")\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "Xtest=X_test[:,0,:,:]\n",
    "Xtest_new = np.repeat(Xtest[..., np.newaxis], 3, -1)\n",
    "print(Xtest_new.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = finetune_model.evaluate(Xtest_new, Y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.22022876739502, 0.49]\n"
     ]
    }
   ],
   "source": [
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [\"0\", \"1\"]\n",
    "FC_LAYERS = [1024, 1024]\n",
    "dropout = 0.5\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      fc_layers=FC_LAYERS, \n",
    "                                      num_classes=len(class_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00001)\n",
    "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 86s 429ms/step - loss: 1.5421 - acc: 0.5100\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 84s 419ms/step - loss: 1.1365 - acc: 0.5850\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 87s 436ms/step - loss: 0.6412 - acc: 0.7450\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 87s 434ms/step - loss: 0.4914 - acc: 0.7950\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 85s 423ms/step - loss: 0.3864 - acc: 0.8600\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 94s 471ms/step - loss: 0.3197 - acc: 0.8750\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 84s 421ms/step - loss: 0.2717 - acc: 0.8950\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 83s 415ms/step - loss: 0.2389 - acc: 0.9050\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 83s 415ms/step - loss: 0.2517 - acc: 0.9050\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 84s 422ms/step - loss: 0.0984 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c433c0cf8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "finetune_model.fit(rgb_batch, Y_train, batch_size=32, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7427052509784698, 0.51]\n"
     ]
    }
   ],
   "source": [
    "score2 = finetune_model.evaluate(Xtest_new, Y_test, verbose=0)\n",
    "print(score2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = [\"0\", \"1\"]\n",
    "FC_LAYERS = [1024, 1024]\n",
    "dropout = 0.5\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      fc_layers=FC_LAYERS, \n",
    "                                      num_classes=len(class_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00001)\n",
    "finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 31s 15s/step - loss: 3.0074 - acc: 0.4305 - val_loss: 0.7369 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 30s 15s/step - loss: 2.9809 - acc: 0.4749 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 34s 17s/step - loss: 2.8912 - acc: 0.5625 - val_loss: 0.6981 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 32s 16s/step - loss: 2.7417 - acc: 0.4862 - val_loss: 0.7003 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 33s 17s/step - loss: 2.9769 - acc: 0.4531 - val_loss: 0.6992 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 28s 14s/step - loss: 3.1640 - acc: 0.4467 - val_loss: 0.6968 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 28s 14s/step - loss: 2.8834 - acc: 0.4377 - val_loss: 0.6956 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 28s 14s/step - loss: 2.8975 - acc: 0.5557 - val_loss: 0.6944 - val_acc: 0.6111\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 31s 15s/step - loss: 3.1555 - acc: 0.5312 - val_loss: 0.6952 - val_acc: 0.5556\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 28s 14s/step - loss: 2.6539 - acc: 0.4952 - val_loss: 0.6967 - val_acc: 0.5556\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BS = 32\n",
    "H = finetune_model.fit_generator(aug.flow(rgb_batch[:90]+rgb_batch[-90:], Y_train[:90]+Y_train[-90:], batch_size=BS),\n",
    "                                 validation_data=(rgb_batch[91:109], Y_train[91:109]), \n",
    "                                 steps_per_epoch=len(rgb_batch[:90]+rgb_batch[-90:]) // BS,epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6891342234611512, 0.52]\n"
     ]
    }
   ],
   "source": [
    "score3 = finetune_model.evaluate(Xtest_new, Y_test, verbose=0)\n",
    "print(score3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
